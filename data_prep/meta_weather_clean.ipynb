{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from webapp.utils.azure_utils import KeyVault, DataLake\n",
    "from webapp.utils.data_pre_utils import df_val_map\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Storage Account\n",
    "vault = KeyVault(keyVaultName = \"keyvaultdva2022\")\n",
    "storage_credential = vault.get_secret(secretName = \"storagePrimaryKey\")\n",
    "storage = DataLake(account_name = \"storageaccountdva\", credential = storage_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_system = \"energyhub\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = storage.pandas_read(file_system, directory=\"data_original/metadata\", file_name=\"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names:\n",
    "meta_data = meta_data.rename(columns = {'building_id': 'building_id',\n",
    "                    'site_id': 'site_id',\n",
    "                    'building_id_kaggle': 'building_id_kaggle',\n",
    "                    'site_id_kaggle': 'site_id_kaggle',\n",
    "                    'primaryspaceusage': 'primary_space_usage',\n",
    "                    'sub_primaryspaceusage': 'sub_primary_space_usage',\n",
    "                    'sqm': 'sq_meter',\n",
    "                    'sqft': 'sq_feet',\n",
    "                    'lat': 'latitude',\n",
    "                    'lng': 'longitude',\n",
    "                    'timezone': 'timezone',\n",
    "                    'electricity': 'electricity',\n",
    "                    'hotwater': 'hotwater',\n",
    "                    'chilledwater': 'chilledwater',\n",
    "                    'steam': 'steam',\n",
    "                    'water': 'water',\n",
    "                    'irrigation': 'irrigation',\n",
    "                    'solar': 'solar',\n",
    "                    'gas': 'gas',\n",
    "                    'industry': 'industry',\n",
    "                    'subindustry': 'subindustry',\n",
    "                    'heatingtype': 'heating_type',\n",
    "                    'yearbuilt': 'year_built',\n",
    "                    'date_opened': 'date_opened',\n",
    "                    'numberoffloors': 'number_of_floors',\n",
    "                    'occupants': 'occupants',\n",
    "                    'energystarscore': 'energy_stars_core',\n",
    "                    'eui': 'eui',\n",
    "                    'site_eui': 'site_eui',\n",
    "                    'source_eui': 'source_eui',\n",
    "                    'leed_level': 'leed_level',\n",
    "                    'rating': 'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map values with Yes flag:\n",
    "mapping_values = {'Yes': True, np.nan: False}\n",
    "cols_to_map = [\"electricity\", \"hotwater\", \"chilledwater\", \"steam\", \"water\", \"irrigation\", \"solar\", \"gas\"]\n",
    "\n",
    "for col in cols_to_map:\n",
    "    df_val_map(meta_data, col, mapping_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types:\n",
    "meta_data= meta_data.astype({'building_id': 'category', \n",
    "                'site_id': 'category', \n",
    "                'building_id_kaggle': 'category',\n",
    "                'site_id_kaggle': 'category',\n",
    "                'primary_space_usage': 'category', \n",
    "                'sub_primary_space_usage': 'category',\n",
    "                'sq_meter': 'float64',\n",
    "                'sq_feet': 'float64',\n",
    "                'latitude': 'float64',\n",
    "                'longitude': 'float64',\n",
    "                'timezone': 'category',\n",
    "                'electricity': 'bool_',\n",
    "                'hotwater': 'bool_',\n",
    "                'chilledwater': 'bool_', \n",
    "                'steam': 'bool_',\n",
    "                'water': 'bool_', \n",
    "                'irrigation': 'bool_', \n",
    "                'solar': 'bool_',\n",
    "                'gas': 'bool_',\n",
    "                'industry': 'category',\n",
    "                'subindustry': 'category',\n",
    "                'heating_type': 'category', \n",
    "                'year_built': 'category',\n",
    "                'date_opened': 'category',\n",
    "                'number_of_floors':'int64', \n",
    "                'occupants': 'int64',\n",
    "                'energy_stars_core': 'category',\n",
    "                'eui': 'category', \n",
    "                'site_eui': 'category',\n",
    "                'source_eui': 'category', \n",
    "                'leed_level': 'category', \n",
    "                'rating': 'category'}, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index:\n",
    "#meta_data = meta_data.set_index(\"building_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.parq write complete\n"
     ]
    }
   ],
   "source": [
    "file_system = \"energyhub\"\n",
    "file_name = \"metadata.parq\"\n",
    "directory = \"data_parq/metadata\"\n",
    "\n",
    "meta_data.to_parquet(path = file_name, engine = \"pyarrow\", compression = \"gzip\", index = False)\n",
    "storage.upload(file_system, directory = directory, file_name = file_name, file_path = file_name, overwrite=True)\n",
    "os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = storage.pandas_read(file_system, directory=\"data_original/weather\", file_name=\"weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.rename(columns = {'timestamp': 'timestamp',\n",
    "            'site_id': 'site_id',\n",
    "            'airTemperature': 'air_temperature',\n",
    "            'cloudCoverage': 'cloud_coverage',\n",
    "            'dewTemperature': 'dew_temperature',\n",
    "            'precipDepth1HR': 'precipitation_depth_1_hr',\n",
    "            'precipDepth6HR': 'precipitation_depth_6_hr',\n",
    "            'seaLvlPressure': 'sea_level_pressure',\n",
    "            'windDirection': 'wind_direction',\n",
    "            'windSpeed': 'wind_speed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.astype({'timestamp': 'datetime64[ns]', \n",
    "        'site_id': 'category', \n",
    "        'air_temperature': 'float64', \n",
    "        'cloud_coverage': 'category',\n",
    "        'dew_temperature': 'float64', \n",
    "        'precipitation_depth_1_hr': 'float64',\n",
    "        'precipitation_depth_6_hr': 'float64',\n",
    "        'sea_level_pressure': 'float64',\n",
    "        'wind_direction': 'float64',\n",
    "        'wind_speed': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index: \n",
    "#weather = weather.set_index([\"timestamp\", \"site_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather.parq write complete\n"
     ]
    }
   ],
   "source": [
    "file_system = \"energyhub\"\n",
    "file_name = \"weather.parq\"\n",
    "directory = \"data_parq/weather\"\n",
    "\n",
    "weather.to_parquet(path = file_name, engine = \"pyarrow\", compression = \"gzip\", index = False)\n",
    "storage.upload(file_system, directory = directory, file_name = file_name, file_path = file_name, overwrite=True)\n",
    "os.remove(file_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a36958482b636de30c6f22e27dd07f9205d77a571c040a53f5dd2b190cea407e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
